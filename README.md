

# Shea-Brown Research Lab

### RNN Latent Structure

In the paper [Signatures and mechanisms of low-dimensional neural predictive manifolds](https://www.biorxiv.org/content/10.1101/471987v1) by Stefano Recanatesi et al. they found evidence that
training a recurrent neural network (RNN) in a predictive task allowed it to extract some of the underlying structure of the system. More specifically, given an agent that moves throughout some sort of
environment collecting observations about the system, train the RNN to attempt to predict the observation the agent collects during the next time step. In doing so, the agent collects some underlying information
about the system which these observations are related to in an attempt to store a low-dimensional representation of the system. In this first project, we are interested in exploring the underlying structure of
new systems to see if we can learn more about them
